This project had the goal to train a robust model, locally using dedicated RTX GPU on custom data, that will be able to detect early fire and smoke to prevent wildfire. 

All images are collected randomly from Google images. To speed up a process a little bit, I was using GoogleImageCrawler that helped me to download batches of 50 images instantly in separate folder files. I shared script you can just change search keyword and get new images (fire, small fire, wildfire, fire in the woods etc...). After all images were downloaded, I grouped them in one folder. Then using script rename_images.py (also shared in this repository) all images were renamed from 1 to 276 respectively. From these images, 250 images were selected for training and the rest for validation purpose. 

Both train and validation images were manually annotated using labeling that is a free app downloaded from GitHub repository link https://github.com/HumanSignal/labelImg. Two types of objects were annotated for model training, fire and smoke. For YOLO model training it is important to create exact folder structure and the config.yaml file that follows that structure, so under "data" folder there should be two folders one under name "images" and the other one under name "labels". In both folder (images and labels) are two separate folders, one under name "train" and the other one under name "valid". During annotations with labelImg all annotated files should be stored in a YOLO format under .txt extension (you have option in labeling to chose YOLO instead Pascal VOC). Each image that is stored in images folder has a .txt file with the same name in labels folder. Also after you annotate all images, regarding that it is time-consuming, manual and sometimes tedious process mistakes can happen (saving not annotated files or files with wrong classes). I also uploaded find_bad_annotations.py script that will go through folder you select (just change for your absolute path) and mark all suspected files that have more classes than stated in predefined_classes.txt file (it comes with installation of labelImg), in my case I just fill in with two classes I want to annotate, fire and smoke and also this script will find empty annotated file and marked them so you can come back again and annotate again if you saved them by mistakes (these files if you leave them will interrupt with model training later). 

Next step is to create config.yaml file (I shared it in repository). Most important to check your absolute path for data folder and then write relative paths for train and valid folder. Also, the crucial is for number of classes that it must mach predefined_classes.txt file number of classes and names. 

Now you are ready for training. For this project, I used my own GPU and trained the model locally. If you have NVIDIA GPU and CUDA installed and available you can train the model locally, just be aware of VRAM memory to not be surpassed by the memory of training images that you are loading. Using training.py script you can download YOLOv8 model, write number of epochs that you want to train (change also other hyperparameters if you are not satisfied with default one) and if your config.yaml file is correct, model will start with training. The other option is to use Google Colab GPU and train model on their instance (I used this technique in my previous project). 

After model finish training you will get new folder under name "run" in your project file (or Google Drive if you are doing it on Google Colab instance) and in that folder under folder named "weights" you will get file "best.pt" Those are best model weights in PyTorch format that are stored after model finish with training. You will use those weights (or first download from Google Colab then use it locally) for predictions. Beside that in runs folder you can find some other files in terms of graphs (descriptive statistics of your model performance) and .jpg files that were stored during model training in batches(I shared some of them as train_batch.jpg images). 

At the end, you can use script main.py that will import best.pt model weights. Script is written for both testing your model on videos or images (just change code use_video = True to False if you are using it on images). Regarding that best.pt file have size bigger than 200 megabytes I will not share it in this repository, you will get model weights if you train like described above. 

I will share results.jpg and results.mp4 of testing model on totally new random images and videos after training.  